#!/usr/bin/env python3
"""
å¢å¼ºäº§èƒ½åˆ†æå™¨ - Enhanced Capacity Analyzer

åŸºäºDaily Planæ•°æ®çš„æ™ºèƒ½äº§èƒ½åˆ†æå·¥å…·ï¼Œç”¨äºå‡†ç¡®è·å–äº§çº¿å®é™…äº§èƒ½ä¿¡æ¯
æ”¯æŒå¤šsheetåˆ†æã€å†å²æ•°æ®èåˆã€äº§èƒ½è¶‹åŠ¿åˆ†æç­‰åŠŸèƒ½
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Any, Tuple, Optional
import logging
from datetime import datetime
import os

class EnhancedCapacityAnalyzer:
    """
    å¢å¼ºäº§èƒ½åˆ†æå™¨
    
    ä»Daily Planæ•°æ®ä¸­æ™ºèƒ½åˆ†æå’Œæ¨ç®—å„äº§çº¿çš„å®é™…äº§èƒ½
    æä¾›å¤šç§äº§èƒ½è·å–ç­–ç•¥å’Œæ•°æ®éªŒè¯åŠŸèƒ½
    """
    
    def __init__(self, data_dir: str = "data"):
        """
        åˆå§‹åŒ–äº§èƒ½åˆ†æå™¨
        
        Args:
            data_dir: æ•°æ®æ–‡ä»¶ç›®å½•
        """
        self.data_dir = data_dir
        self.daily_plan_file = os.path.join(data_dir, "daily plan.xlsx")
        self.capacity_file = os.path.join(data_dir, "capacity .xlsx")
        
        # è®¾ç½®æ—¥å¿—
        self.logger = self._setup_logger()
        
        # äº§èƒ½åˆ†æç»“æœç¼“å­˜
        self.capacity_cache = {}
        
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger('CapacityAnalyzer')
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            
        return logger
    
    def analyze_all_production_lines(self) -> Dict[str, Dict[str, Any]]:
        """
        åˆ†ææ‰€æœ‰äº§çº¿çš„äº§èƒ½ä¿¡æ¯
        
        Returns:
            åŒ…å«æ‰€æœ‰äº§çº¿äº§èƒ½åˆ†æç»“æœçš„å­—å…¸
        """
        self.logger.info("ğŸš€ å¼€å§‹åˆ†ææ‰€æœ‰äº§çº¿äº§èƒ½...")
        
        # è·å–æ‰€æœ‰å¯ç”¨çš„sheet
        try:
            xlsx = pd.ExcelFile(self.daily_plan_file)
            sheet_names = xlsx.sheet_names
            self.logger.info(f"å‘ç°Daily Plan sheets: {sheet_names}")
        except Exception as e:
            self.logger.error(f"æ— æ³•è¯»å–Daily Planæ–‡ä»¶: {e}")
            return {}
        
        all_lines_capacity = {}
        
        # åˆ†ææ¯ä¸ªsheet
        for sheet_name in sheet_names:
            self.logger.info(f"\n--- åˆ†æSheet: {sheet_name} ---")
            sheet_analysis = self._analyze_sheet_capacity(sheet_name)
            
            # åˆå¹¶ç»“æœ
            for line, capacity_info in sheet_analysis.items():
                if line not in all_lines_capacity:
                    all_lines_capacity[line] = {
                        'sheets_data': {},
                        'combined_analysis': {}
                    }
                
                all_lines_capacity[line]['sheets_data'][sheet_name] = capacity_info
        
        # ç”Ÿæˆç»¼åˆåˆ†æ
        for line in all_lines_capacity:
            all_lines_capacity[line]['combined_analysis'] = self._generate_combined_analysis(
                line, all_lines_capacity[line]['sheets_data']
            )
        
        self.capacity_cache = all_lines_capacity
        return all_lines_capacity
    
    def _analyze_sheet_capacity(self, sheet_name: str) -> Dict[str, Dict[str, Any]]:
        """
        åˆ†æå•ä¸ªsheetçš„äº§èƒ½æ•°æ®
        
        Args:
            sheet_name: sheetåç§°
            
        Returns:
            äº§çº¿äº§èƒ½åˆ†æç»“æœ
        """
        try:
            # è¯»å–æ•°æ®ï¼Œä½¿ç”¨3çº§è¡¨å¤´
            df = pd.read_excel(self.daily_plan_file, sheet_name=sheet_name, header=[0,1,2])
            
            # è·å–äº§çº¿åˆ—
            line_col = df.iloc[:, 0]
            
            # æ‰¾å‡ºæ‰€æœ‰Fç³»åˆ—äº§çº¿
            f_lines = [line for line in line_col.dropna().unique() 
                      if isinstance(line, str) and line.startswith('F') and line != 'Forecast']
            
            sheet_capacity = {}
            
            for line in f_lines:
                capacity_info = self._analyze_line_capacity_in_sheet(df, line, sheet_name)
                if capacity_info:
                    sheet_capacity[line] = capacity_info
            
            return sheet_capacity
            
        except Exception as e:
            self.logger.error(f"åˆ†æsheet {sheet_name} æ—¶å‡ºé”™: {e}")
            return {}
    
    def _analyze_line_capacity_in_sheet(self, df: pd.DataFrame, line: str, sheet_name: str) -> Optional[Dict[str, Any]]:
        """
        åˆ†æç‰¹å®šäº§çº¿åœ¨ç‰¹å®šsheetä¸­çš„äº§èƒ½
        
        Args:
            df: Daily Planæ•°æ®æ¡†
            line: äº§çº¿åç§°
            sheet_name: sheetåç§°
            
        Returns:
            äº§çº¿äº§èƒ½åˆ†æç»“æœ
        """
        line_col = df.iloc[:, 0]
        line_mask = line_col == line
        line_data = df[line_mask]
        
        if len(line_data) == 0:
            return None
        
        # æ”¶é›†æ‰€æœ‰äº§é‡æ•°æ®
        all_productions = []
        shift_productions = {}
        product_productions = {}
        
        for _, row in line_data.iterrows():
            # è·å–äº§å“ä¿¡æ¯
            build_type = row.iloc[1] if len(row) > 1 else 'Unknown'
            part_number = row.iloc[2] if len(row) > 2 else 'Unknown'
            
            # åˆ†æç”Ÿäº§æ•°æ®åˆ—ï¼ˆè·³è¿‡å‰3åˆ—å’Œæœ€åçš„Totalåˆ—ï¼‰
            for j in range(3, len(row)-1):
                val = row.iloc[j]
                if pd.notna(val) and val > 0:
                    all_productions.append(val)
                    
                    # è§£æç­æ¬¡ä¿¡æ¯
                    col_tuple = df.columns[j]
                    if len(col_tuple) >= 3:
                        date_info = col_tuple[0]
                        weekday = col_tuple[1]
                        shift = col_tuple[2]
                        shift_key = f"{weekday}_{shift}"
                        
                        if shift_key not in shift_productions:
                            shift_productions[shift_key] = []
                        shift_productions[shift_key].append(val)
                        
                        # æŒ‰äº§å“ç»Ÿè®¡
                        if build_type not in product_productions:
                            product_productions[build_type] = []
                        product_productions[build_type].append(val)
        
        if not all_productions:
            return {
                'max_shift_output': 0,
                'avg_shift_output': 0,
                'total_output': 0,
                'active_shifts': 0,
                'products': [],
                'confidence': 0.0,
                'data_quality': 'No production data'
            }
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        max_production = max(all_productions)
        avg_production = np.mean(all_productions)
        total_production = sum(all_productions)
        active_shifts = len(all_productions)
        
        # åˆ†æç­æ¬¡æ¨¡å¼
        shift_analysis = {}
        for shift_key, productions in shift_productions.items():
            shift_analysis[shift_key] = {
                'max': max(productions),
                'avg': np.mean(productions),
                'count': len(productions)
            }
        
        # äº§å“åˆ†æ
        product_analysis = {}
        for product, productions in product_productions.items():
            product_analysis[product] = {
                'max': max(productions),
                'avg': np.mean(productions),
                'count': len(productions)
            }
        
        # æ•°æ®è´¨é‡è¯„ä¼°
        data_quality = self._assess_data_quality(all_productions, active_shifts)
        
        # ç½®ä¿¡åº¦è®¡ç®—
        confidence = self._calculate_confidence(all_productions, active_shifts, len(line_data))
        
        return {
            'max_shift_output': max_production,
            'avg_shift_output': avg_production,
            'total_output': total_production,
            'active_shifts': active_shifts,
            'shift_analysis': shift_analysis,
            'product_analysis': product_analysis,
            'products': list(product_productions.keys()),
            'confidence': confidence,
            'data_quality': data_quality,
            'raw_data': all_productions
        }
    
    def _assess_data_quality(self, productions: List[float], active_shifts: int) -> str:
        """è¯„ä¼°æ•°æ®è´¨é‡"""
        if not productions:
            return "No data"
        
        if active_shifts >= 10:
            return "High quality"
        elif active_shifts >= 5:
            return "Medium quality"
        elif active_shifts >= 2:
            return "Low quality"
        else:
            return "Very low quality"
    
    def _calculate_confidence(self, productions: List[float], active_shifts: int, line_rows: int) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦"""
        if not productions:
            return 0.0
        
        # åŸºäºæ•°æ®é‡çš„ç½®ä¿¡åº¦
        data_confidence = min(1.0, active_shifts / 10.0)
        
        # åŸºäºæ•°æ®ä¸€è‡´æ€§çš„ç½®ä¿¡åº¦
        if len(productions) > 1:
            cv = np.std(productions) / np.mean(productions)  # å˜å¼‚ç³»æ•°
            consistency_confidence = max(0.0, 1.0 - cv)
        else:
            consistency_confidence = 0.5
        
        # åŸºäºäº§çº¿é…ç½®æ•°çš„ç½®ä¿¡åº¦
        config_confidence = min(1.0, line_rows / 3.0)
        
        # ç»¼åˆç½®ä¿¡åº¦
        total_confidence = (data_confidence * 0.5 + consistency_confidence * 0.3 + config_confidence * 0.2)
        
        return round(total_confidence, 2)
    
    def _generate_combined_analysis(self, line: str, sheets_data: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """
        ç”Ÿæˆå¤šsheetçš„ç»¼åˆåˆ†æç»“æœ
        
        Args:
            line: äº§çº¿åç§°
            sheets_data: å„sheetçš„åˆ†ææ•°æ®
            
        Returns:
            ç»¼åˆåˆ†æç»“æœ
        """
        all_max_outputs = []
        all_avg_outputs = []
        all_products = set()
        total_active_shifts = 0
        weighted_confidence = 0
        
        for sheet_name, data in sheets_data.items():
            if data['max_shift_output'] > 0:
                all_max_outputs.append(data['max_shift_output'])
                all_avg_outputs.append(data['avg_shift_output'])
                total_active_shifts += data['active_shifts']
                weighted_confidence += data['confidence'] * data['active_shifts']
                all_products.update(data['products'])
        
        if not all_max_outputs:
            return {
                'recommended_capacity': 0,
                'capacity_range': (0, 0),
                'data_source': 'No data available',
                'confidence': 0.0,
                'products': []
            }
        
        # æ¨èäº§èƒ½è®¡ç®—
        max_observed = max(all_max_outputs)
        avg_max = np.mean(all_max_outputs)
        
        # åº”ç”¨äº§èƒ½ç³»æ•° (åŸºäºæ•°æ®è´¨é‡è°ƒæ•´)
        avg_confidence = weighted_confidence / total_active_shifts if total_active_shifts > 0 else 0
        capacity_factor = 1.1 + (0.2 * avg_confidence)  # 1.1 åˆ° 1.3 ä¹‹é—´
        
        recommended_capacity = max_observed * capacity_factor
        
        # äº§èƒ½èŒƒå›´
        min_capacity = max_observed * 1.05
        max_capacity = max_observed * 1.4
        
        return {
            'recommended_capacity': round(recommended_capacity, 0),
            'capacity_range': (round(min_capacity, 0), round(max_capacity, 0)),
            'max_observed_output': max_observed,
            'avg_max_output': round(avg_max, 1),
            'total_active_shifts': total_active_shifts,
            'data_source': f"Daily Plan analysis ({len(sheets_data)} sheets)",
            'confidence': round(avg_confidence, 2),
            'products': list(all_products),
            'capacity_factor': round(capacity_factor, 2)
        }
    
    def get_line_capacity(self, target_line: str) -> Dict[str, Any]:
        """
        è·å–æŒ‡å®šäº§çº¿çš„äº§èƒ½ä¿¡æ¯
        
        Args:
            target_line: ç›®æ ‡äº§çº¿
            
        Returns:
            äº§èƒ½åˆ†æç»“æœ
        """
        # å¦‚æœè¿˜æ²¡æœ‰åˆ†æè¿‡ï¼Œå…ˆè¿›è¡Œå…¨é‡åˆ†æ
        if not self.capacity_cache:
            self.analyze_all_production_lines()
        
        # æŸ¥æ‰¾ç›®æ ‡äº§çº¿
        for line, capacity_data in self.capacity_cache.items():
            if target_line in line:
                result = capacity_data['combined_analysis'].copy()
                result['line'] = line
                result['detailed_data'] = capacity_data['sheets_data']
                return result
        
        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œè¿”å›é»˜è®¤ä¿¡æ¯
        return {
            'line': target_line,
            'recommended_capacity': 8000,
            'capacity_range': (7000, 9000),
            'data_source': 'Default fallback',
            'confidence': 0.0,
            'products': []
        }
    
    def generate_capacity_report(self) -> str:
        """
        ç”Ÿæˆäº§èƒ½åˆ†ææŠ¥å‘Š
        
        Returns:
            æ ¼å¼åŒ–çš„äº§èƒ½æŠ¥å‘Šå­—ç¬¦ä¸²
        """
        if not self.capacity_cache:
            self.analyze_all_production_lines()
        
        report = ["=" * 80]
        report.append("äº§çº¿äº§èƒ½åˆ†ææŠ¥å‘Š")
        report.append("=" * 80)
        report.append(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"åˆ†æäº§çº¿æ•°é‡: {len(self.capacity_cache)}")
        report.append("")
        
        # æŒ‰äº§çº¿æ’åº
        sorted_lines = sorted(self.capacity_cache.keys())
        
        for line in sorted_lines:
            data = self.capacity_cache[line]
            combined = data['combined_analysis']
            
            report.append(f"ğŸ“ {line}äº§çº¿")
            report.append("-" * 40)
            report.append(f"æ¨èäº§èƒ½: {combined.get('recommended_capacity', 0):.0f}")
            report.append(f"äº§èƒ½èŒƒå›´: {combined.get('capacity_range', (0, 0))}")
            report.append(f"æœ€å¤§è§‚æµ‹äº§é‡: {combined.get('max_observed_output', 0):.0f}")
            report.append(f"æ•°æ®æ¥æº: {combined.get('data_source', 'Unknown')}")
            report.append(f"ç½®ä¿¡åº¦: {combined.get('confidence', 0):.2f}")
            report.append(f"æ”¯æŒäº§å“: {', '.join(combined.get('products', []))}")
            
            # å„sheetè¯¦æƒ…
            report.append("  å„Sheetæ•°æ®:")
            for sheet_name, sheet_data in data['sheets_data'].items():
                report.append(f"    {sheet_name}: æœ€å¤§{sheet_data['max_shift_output']}, "
                             f"å¹³å‡{sheet_data['avg_shift_output']:.1f}, "
                             f"ç­æ¬¡{sheet_data['active_shifts']}, "
                             f"è´¨é‡{sheet_data['data_quality']}")
            
            report.append("")
        
        return "\n".join(report)

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºäº§èƒ½åˆ†æå™¨çš„ä½¿ç”¨"""
    
    print("ğŸš€ å¯åŠ¨å¢å¼ºäº§èƒ½åˆ†æå™¨...")
    
    analyzer = EnhancedCapacityAnalyzer()
    
    # åˆ†ææ‰€æœ‰äº§çº¿
    results = analyzer.analyze_all_production_lines()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_capacity_report()
    print(report)
    
    # ç‰¹å®šäº§çº¿æŸ¥è¯¢ç¤ºä¾‹
    print("\n" + "=" * 60)
    print("ç‰¹å®šäº§çº¿æŸ¥è¯¢ç¤ºä¾‹")
    print("=" * 60)
    
    for line in ['F25', 'F29', 'F16']:
        print(f"\nğŸ” æŸ¥è¯¢{line}äº§çº¿äº§èƒ½:")
        capacity_info = analyzer.get_line_capacity(line)
        print(f"  æ¨èäº§èƒ½: {capacity_info.get('recommended_capacity', 0)}")
        print(f"  ç½®ä¿¡åº¦: {capacity_info.get('confidence', 0)}")
        print(f"  æ•°æ®æ¥æº: {capacity_info.get('data_source', 'Unknown')}")

if __name__ == "__main__":
    main()