"""
LCAäº§èƒ½æŸå¤±å¤„ç†æ¨¡å—
LCA Capacity Loss Processing Module

ä¸“é—¨å¤„ç†LCAäº§èƒ½æŸå¤±äº‹ä»¶çš„ä¸šåŠ¡é€»è¾‘æ¨¡å—
"""

import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Any, Tuple, Optional
import logging


class LCACapacityLossProcessor:
    """
    LCAäº§èƒ½æŸå¤±å¤„ç†å™¨
    
    è´Ÿè´£å¤„ç†LCAäº§èƒ½æŸå¤±äº‹ä»¶çš„å…·ä½“ä¸šåŠ¡é€»è¾‘
    åŒ…æ‹¬äº§èƒ½æŸå¤±è®¡ç®—ã€å½±å“åˆ†æã€è¡¥å¿æ–¹æ¡ˆç”Ÿæˆç­‰
    """
    
    def __init__(self, data_loader, logger=None):
        """
        åˆå§‹åŒ–LCAäº§èƒ½æŸå¤±å¤„ç†å™¨
        
        Args:
            data_loader: æ•°æ®åŠ è½½å™¨å®ä¾‹
            logger: æ—¥å¿—è®°å½•å™¨
        """
        self.data_loader = data_loader
        self.logger = logger or logging.getLogger(__name__)
        
    def process_lca_capacity_loss(self, event_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¤„ç†LCAäº§èƒ½æŸå¤±äº‹ä»¶çš„ä¸»è¦å…¥å£å‡½æ•°
        
        Args:
            event_data: äº‹ä»¶æ•°æ®å­—å…¸
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        self.logger.info("=" * 60)
        self.logger.info("ğŸš€ å¼€å§‹å¤„ç†LCAäº§èƒ½æŸå¤±äº‹ä»¶")
        self.logger.info(f"ğŸ“‹ å½“å‰äº‹ä»¶ä¿¡æ¯: æ—¥æœŸ={event_data.get('é€‰æ‹©å½±å“æ—¥æœŸ')}, ç­æ¬¡={event_data.get('é€‰æ‹©å½±å“ç­æ¬¡')}, äº§çº¿={event_data.get('é€‰æ‹©äº§çº¿')}")
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šæ£€æŸ¥å‰3ä¸ªç­æ¬¡éƒ½æœ‰æŠ¥å‘ŠæŸå¤±ï¼Œä¸”ç´¯è®¡æŸå¤±è¶…è¿‡10K
            self.logger.info("ğŸ” æ­¥éª¤1: å¼€å§‹æ£€æŸ¥å‰3ä¸ªç­æ¬¡çš„æŸå¤±æƒ…å†µ...")
            check_result = self._check_previous_shifts_loss(event_data)
            
            self.logger.info(f"ğŸ“Š æ£€æŸ¥ç»“æœç»Ÿè®¡:")
            self.logger.info(f"   - æ£€æŸ¥ç­æ¬¡æ•°: {check_result.get('shifts_checked', 0)}")
            self.logger.info(f"   - æœ‰æŸå¤±ç­æ¬¡: {check_result.get('shifts_with_loss', 0)}")
            self.logger.info(f"   - ç´¯è®¡æŸå¤±: {check_result.get('total_loss', 0):.0f}")
            self.logger.info(f"   - æ‰€æœ‰ç­æ¬¡éƒ½æœ‰æŸå¤±: {check_result.get('all_shifts_have_loss', False)}")
            self.logger.info(f"   - æŸå¤±è¶…è¿‡10K: {check_result.get('total_exceeds_10k', False)}")
            
            if check_result["has_sufficient_loss"]:
                self.logger.info("âœ… åˆ¤å®šç»“æœ: å‰3ä¸ªç­æ¬¡ç´¯è®¡æŸå¤±è¶…è¿‡10Kï¼Œå»ºè®®åŠ çº¿")
                self.logger.info("ğŸ­ è¾“å‡ºå»ºè®®: äº§çº¿çŠ¶å†µä¸ä½³ï¼Œè€ƒè™‘åŠ çº¿")
                return {
                    "status": "add_line_required",
                    "message": "äº§çº¿çŠ¶å†µä¸ä½³ï¼Œè€ƒè™‘åŠ çº¿",
                    "step": "æ£€æŸ¥å‰3ç­æ¬¡æŸå¤±",
                    "check_result": check_result,
                    "recommendation": "åŠ çº¿",
                    "event_data": event_data
                }
            else:
                self.logger.info("â„¹ï¸  åˆ¤å®šç»“æœ: æœªè¾¾åˆ°åŠ çº¿æ¡ä»¶ï¼Œç»§ç»­æ­£å¸¸æµç¨‹")
                self.logger.info(f"ğŸ“ åŸå› : {check_result.get('reason', 'æœªçŸ¥')}")
                return {
                    "status": "normal_process",
                    "message": "æŸå¤±åœ¨æ­£å¸¸èŒƒå›´å†…ï¼ŒæŒ‰æ ‡å‡†æµç¨‹å¤„ç†",
                    "step": "æ£€æŸ¥å‰3ç­æ¬¡æŸå¤±",
                    "check_result": check_result,
                    "recommendation": "æ ‡å‡†å¤„ç†",
                    "event_data": event_data
                }
            
        except Exception as e:
            error_msg = f"å¤„ç†LCAäº§èƒ½æŸå¤±äº‹ä»¶å¤±è´¥: {str(e)}"
            self.logger.error(f"âŒ {error_msg}")
            return {
                "status": "error",
                "message": error_msg,
                "event_data": event_data
            }
        finally:
            self.logger.info("=" * 60)
    
    def _check_previous_shifts_loss(self, event_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ£€æŸ¥å‰3ä¸ªç­æ¬¡éƒ½æœ‰æŠ¥å‘ŠæŸå¤±ï¼Œä¸”ç´¯è®¡æŸå¤±è¶…è¿‡10K
        
        Args:
            event_data: å½“å‰äº‹ä»¶æ•°æ®
            
        Returns:
            æ£€æŸ¥ç»“æœå­—å…¸
        """
        self.logger.info("æ£€æŸ¥å‰3ä¸ªç­æ¬¡çš„æŸå¤±æƒ…å†µ...")
        
        try:
            # è·å–å½“å‰äº‹ä»¶çš„äº§çº¿ä¿¡æ¯
            current_line = event_data.get('é€‰æ‹©äº§çº¿')
            current_date = event_data.get('é€‰æ‹©å½±å“æ—¥æœŸ')
            current_shift = event_data.get('é€‰æ‹©å½±å“ç­æ¬¡')
            
            if not all([current_line, current_date, current_shift]):
                return {
                    "has_sufficient_loss": False,
                    "reason": "äº‹ä»¶ä¿¡æ¯ä¸å®Œæ•´",
                    "previous_shifts": [],
                    "total_loss": 0
                }
            
            # è·å–Daily Planæ•°æ®ï¼ˆä½¿ç”¨ä¸‰çº§è¡¨å¤´ï¼‰
            daily_plan_data = self._get_daily_plan_with_shifts()
            if daily_plan_data is None:
                return {
                    "has_sufficient_loss": False,
                    "reason": "æ— æ³•è·å–Daily Planæ•°æ®",
                    "previous_shifts": [],
                    "total_loss": 0
                }
            
            # è·å–å‰3ä¸ªç­æ¬¡çš„ä¿¡æ¯
            previous_shifts = self._get_previous_3_shifts(current_date, current_shift)
            self.logger.info(f"ğŸ“… è®¡ç®—å¾—å‡ºå‰3ä¸ªç­æ¬¡:")
            for i, shift in enumerate(previous_shifts, 1):
                self.logger.info(f"   {i}. {shift['date']} {shift['shift']}")
            
            # æ£€æŸ¥æ¯ä¸ªç­æ¬¡æ˜¯å¦æœ‰æŸå¤±æŠ¥å‘Š
            self.logger.info(f"ğŸ” å¼€å§‹æŸ¥è¯¢å„ç­æ¬¡çš„æŸå¤±æ•°æ®...")
            shifts_with_loss = []
            total_loss = 0
            
            for i, shift_info in enumerate(previous_shifts, 1):
                self.logger.info(f"   æŸ¥è¯¢ç¬¬{i}ä¸ªç­æ¬¡: {shift_info['date']} {shift_info['shift']}")
                loss_data = self._get_shift_loss_data(shift_info, current_line, daily_plan_data)
                
                if loss_data["has_loss"]:
                    shifts_with_loss.append(loss_data)
                    total_loss += loss_data["loss_amount"]
                    self.logger.info(f"   âœ… æ‰¾åˆ°æŸå¤±è®°å½•: {loss_data['loss_amount']:.0f}")
                else:
                    self.logger.info(f"   âŒ æ— æŸå¤±è®°å½•: {loss_data.get('reason', 'æœªæ‰¾åˆ°åŒ¹é…äº‹ä»¶')}")
            
            # åˆ¤æ–­æ˜¯å¦æ»¡è¶³æ¡ä»¶ï¼šå‰3ä¸ªç­æ¬¡éƒ½æœ‰æŸå¤±æŠ¥å‘Š ä¸” ç´¯è®¡æŸå¤±è¶…è¿‡10K
            all_shifts_have_loss = len(shifts_with_loss) >= 3
            total_exceeds_10k = total_loss > 10000
            
            result = {
                "has_sufficient_loss": all_shifts_have_loss and total_exceeds_10k,
                "all_shifts_have_loss": all_shifts_have_loss,
                "total_exceeds_10k": total_exceeds_10k,
                "total_loss": total_loss,
                "shifts_checked": len(previous_shifts),
                "shifts_with_loss": len(shifts_with_loss),
                "previous_shifts": previous_shifts,
                "loss_details": shifts_with_loss,
                "reason": self._get_check_reason(all_shifts_have_loss, total_exceeds_10k, total_loss)
            }
            
            self.logger.info(f"æ£€æŸ¥ç»“æœ: {result['reason']}")
            return result
            
        except Exception as e:
            self.logger.error(f"æ£€æŸ¥å‰3ä¸ªç­æ¬¡æŸå¤±æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return {
                "has_sufficient_loss": False,
                "reason": f"æ£€æŸ¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
                "previous_shifts": [],
                "total_loss": 0
            }
    
    def _get_daily_plan_with_shifts(self) -> Optional[pd.DataFrame]:
        """
        è·å–åŒ…å«ç­æ¬¡ä¿¡æ¯çš„Daily Planæ•°æ®
        
        Returns:
            å¸¦æœ‰ç­æ¬¡ä¿¡æ¯çš„DataFrameæˆ–None
        """
        try:
            # å°è¯•ä»data_loaderè·å–å·²åŠ è½½çš„æ•°æ®
            daily_plan = self.data_loader.get_data('HSA Daily Plan')
            if daily_plan is not None and not daily_plan.empty:
                return daily_plan
            
            # å¦‚æœæ²¡æœ‰åŠ è½½ï¼Œå°è¯•é‡æ–°åŠ è½½
            success, message, daily_plan = self.data_loader.load_data('HSA Daily Plan')
            if success and daily_plan is not None:
                return daily_plan
            
            # å¦‚æœæ ‡å‡†åŠ è½½å¤±è´¥ï¼Œå°è¯•ç›´æ¥è¯»å–Excelæ–‡ä»¶çš„ä¸‰çº§è¡¨å¤´
            file_path = "data/daily plan.xlsx"
            df_with_shifts = pd.read_excel(file_path, sheet_name=0, header=[0,1,2])
            self.logger.info("æˆåŠŸåŠ è½½å¸¦ç­æ¬¡ä¿¡æ¯çš„Daily Plan")
            return df_with_shifts
            
        except Exception as e:
            self.logger.error(f"è·å–Daily Planæ•°æ®å¤±è´¥: {str(e)}")
            return None
    
    def _get_previous_3_shifts(self, current_date: str, current_shift: str) -> List[Dict[str, str]]:
        """
        è·å–å‰3ä¸ªç­æ¬¡çš„ä¿¡æ¯
        
        Args:
            current_date: å½“å‰æ—¥æœŸ (YYYY-MM-DDæ ¼å¼)
            current_shift: å½“å‰ç­æ¬¡ (T1, T2, T3, T4ç­‰)
            
        Returns:
            å‰3ä¸ªç­æ¬¡çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«æ—¥æœŸå’Œç­æ¬¡ä¿¡æ¯
        """
        # ç­æ¬¡é¡ºåºå®šä¹‰
        shift_order = ['T1', 'T2', 'T3', 'T4']
        
        try:
            from datetime import datetime, timedelta
            current_dt = datetime.strptime(current_date, '%Y-%m-%d')
            
            # æ‰¾åˆ°å½“å‰ç­æ¬¡åœ¨é¡ºåºä¸­çš„ä½ç½®
            try:
                current_shift_index = shift_order.index(current_shift)
            except ValueError:
                # å¦‚æœç­æ¬¡ä¸åœ¨æ ‡å‡†åˆ—è¡¨ä¸­ï¼Œå‡è®¾æ˜¯T1
                current_shift_index = 0
            
            previous_shifts = []
            
            # å‘å‰æ¨3ä¸ªç­æ¬¡
            for i in range(1, 4):  # å‰1ã€2ã€3ä¸ªç­æ¬¡
                shift_index = current_shift_index - i
                date_to_check = current_dt
                
                # å¦‚æœç­æ¬¡ç´¢å¼•ä¸ºè´Ÿï¼Œéœ€è¦å›åˆ°å‰ä¸€å¤©
                while shift_index < 0:
                    shift_index += len(shift_order)
                    date_to_check -= timedelta(days=1)
                
                previous_shifts.append({
                    "date": date_to_check.strftime('%Y-%m-%d'),
                    "shift": shift_order[shift_index],
                    "datetime": date_to_check,
                    "shift_index": shift_index
                })
            
            return previous_shifts
            
        except Exception as e:
            self.logger.error(f"è®¡ç®—å‰3ä¸ªç­æ¬¡æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return []
    
    def _get_shift_loss_data(self, shift_info: Dict[str, str], line: str, daily_plan: pd.DataFrame) -> Dict[str, Any]:
        """
        ä»äº‹ä»¶è¡¨è·å–æŒ‡å®šç­æ¬¡çš„æŸå¤±æ•°æ®
        
        Args:
            shift_info: ç­æ¬¡ä¿¡æ¯å­—å…¸
            line: äº§çº¿åç§°
            daily_plan: Daily Planæ•°æ®
            
        Returns:
            ç­æ¬¡æŸå¤±æ•°æ®
        """
        try:
            date = shift_info["date"]
            shift = shift_info["shift"]
            
            # ä»æ•°æ®åº“æŸ¥è¯¢å†å²LCAæŸå¤±äº‹ä»¶
            from .database_manager import DatabaseManager
            
            # åˆ›å»ºæ•°æ®åº“ç®¡ç†å™¨å®ä¾‹
            db_manager = DatabaseManager("data/events.db")
            
            # æŸ¥è¯¢åŒ¹é…çš„LCAäº‹ä»¶
            matching_events = db_manager.get_lca_events_by_criteria(
                date=date,
                line=line
            )
            
            # æŸ¥æ‰¾åŒ¹é…ç­æ¬¡çš„äº‹ä»¶
            matched_event = None
            for event in matching_events:
                event_shift = event.get("é€‰æ‹©å½±å“ç­æ¬¡")
                if event_shift == shift:
                    matched_event = event
                    break
            
            if matched_event:
                # æå–æŸå¤±æ•°æ®
                loss_amount = matched_event.get("å·²ç»æŸå¤±çš„äº§é‡", 0)
                if loss_amount is None:
                    loss_amount = 0
                
                # å°è¯•è½¬æ¢ä¸ºæ•°å­—
                try:
                    loss_amount = float(loss_amount)
                except (ValueError, TypeError):
                    loss_amount = 0
                
                return {
                    "date": date,
                    "shift": shift,
                    "line": line,
                    "has_loss": loss_amount > 0,
                    "loss_amount": loss_amount,
                    "event_id": matched_event.get("äº‹ä»¶ID", ""),
                    "source": "äº‹ä»¶æ•°æ®åº“",
                    "event_data": matched_event
                }
            else:
                # æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„äº‹ä»¶
                return {
                    "date": date,
                    "shift": shift,
                    "line": line,
                    "has_loss": False,
                    "loss_amount": 0,
                    "source": "äº‹ä»¶æ•°æ®åº“",
                    "reason": f"æœªæ‰¾åˆ°{date} {shift}ç­æ¬¡çš„æŸå¤±äº‹ä»¶"
                }
            
        except Exception as e:
            self.logger.error(f"ä»äº‹ä»¶è¡¨è·å–ç­æ¬¡æŸå¤±æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return {
                "date": shift_info.get("date", ""),
                "shift": shift_info.get("shift", ""),
                "line": line,
                "has_loss": False,
                "loss_amount": 0,
                "source": "é”™è¯¯",
                "error": str(e)
            }
    
    def _get_check_reason(self, all_shifts_have_loss: bool, total_exceeds_10k: bool, total_loss: float) -> str:
        """
        ç”Ÿæˆæ£€æŸ¥ç»“æœçš„è¯´æ˜æ–‡å­—
        
        Args:
            all_shifts_have_loss: æ˜¯å¦æ‰€æœ‰ç­æ¬¡éƒ½æœ‰æŸå¤±
            total_exceeds_10k: æ€»æŸå¤±æ˜¯å¦è¶…è¿‡10K
            total_loss: æ€»æŸå¤±æ•°é‡
            
        Returns:
            è¯´æ˜æ–‡å­—
        """
        if all_shifts_have_loss and total_exceeds_10k:
            return f"å‰3ä¸ªç­æ¬¡éƒ½æœ‰æŸå¤±æŠ¥å‘Šï¼Œç´¯è®¡æŸå¤±{total_loss:.0f}è¶…è¿‡10Kï¼Œå»ºè®®åŠ çº¿"
        elif not all_shifts_have_loss and not total_exceeds_10k:
            return f"å‰3ä¸ªç­æ¬¡ä¸­éƒ¨åˆ†æ²¡æœ‰æŸå¤±æŠ¥å‘Šï¼Œä¸”ç´¯è®¡æŸå¤±{total_loss:.0f}æœªè¶…è¿‡10K"
        elif not all_shifts_have_loss:
            return f"å‰3ä¸ªç­æ¬¡ä¸­éƒ¨åˆ†æ²¡æœ‰æŸå¤±æŠ¥å‘Šï¼Œç´¯è®¡æŸå¤±{total_loss:.0f}"
        else:  # total_exceeds_10k is False
            return f"å‰3ä¸ªç­æ¬¡éƒ½æœ‰æŸå¤±æŠ¥å‘Šï¼Œä½†ç´¯è®¡æŸå¤±{total_loss:.0f}æœªè¶…è¿‡10K"